const { OpenAI } = require('openai');
const { query, get } = require('../database/database');

class AgentManager {
  constructor(openaiApiKey) {
    this.openai = new OpenAI({ apiKey: openaiApiKey });
    this.agents = new Map();
    this.contentFilter = new ContentFilter();
    this.initializeAgents();
  }

  async initializeAgents() {
    try {
      const agents = await query(`
        SELECT * FROM ai_agents WHERE is_active = true
      `);

      console.log(`ğŸ¤– ${agents.rows.length}ê°œì˜ AI ì—ì´ì „íŠ¸ ë¡œë“œë¨`);
    } catch (error) {
      console.error('AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜:', error);
    }
  }

  async generatePost(agentId, context = {}) {
    try {
      const agent = await get(`
        SELECT * FROM ai_agents WHERE agent_id = $1 AND is_active = true
      `, [agentId]);

      if (!agent) {
        throw new Error(`Agent ${agentId} not found or inactive`);
      }

      const prompt = this.buildPostPrompt(agent, context);
      
      // ëª¨ë¸ fallback ì‹œìŠ¤í…œ
      const preferredModel = "gpt-4o-mini-search-preview-2025-03-11";
      const fallbackModel = "gpt-4o-mini";
      
      let completion;
      let modelUsed;
      
      try {
        // search-preview ëª¨ë¸ì€ modelê³¼ messagesë§Œ ì§€ì›
        const requestParams = {
          model: preferredModel,
          messages: [
            { role: "system", content: agent.system_prompt },
            { role: "user", content: prompt }
          ]
        };
        
        // search-preview ëª¨ë¸ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        if (!preferredModel.includes('search-preview')) {
          requestParams.temperature = 0.8;
          requestParams.max_tokens = 2000;
        }
        
        completion = await this.openai.chat.completions.create(requestParams);
        modelUsed = preferredModel;
        console.log(`âœ… ${agent.nickname} - ${preferredModel} ëª¨ë¸ ì‚¬ìš© ì„±ê³µ`);
        
      } catch (modelError) {
        console.warn(`âš ï¸ ${preferredModel} ëª¨ë¸ ì‚¬ìš© ì‹¤íŒ¨: ${modelError.message}`);
        console.log(`ğŸ”„ ${fallbackModel} ëª¨ë¸ë¡œ ì¬ì‹œë„...`);
        
        // fallback ëª¨ë¸ë¡œ ì¬ì‹œë„
        completion = await this.openai.chat.completions.create({
          model: fallbackModel,
          messages: [
            { role: "system", content: agent.system_prompt },
            { role: "user", content: prompt }
          ],
          temperature: 0.8,
          max_tokens: 2000
        });
        modelUsed = fallbackModel;
        console.log(`âœ… ${agent.nickname} - ${fallbackModel} ëª¨ë¸ ì‚¬ìš© (fallback)`);
      }

      const content = completion.choices[0].message.content;
      const finishReason = completion.choices[0].finish_reason;
      
      // í† í° ì œí•œìœ¼ë¡œ ëŠê²¼ëŠ”ì§€ ë¡œê¹…
      if (finishReason === 'length') {
        console.warn(`âš ï¸ ${agent.nickname} ì½˜í…ì¸ ê°€ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤`);
      } else if (finishReason === 'stop') {
        console.log(`âœ… ${agent.nickname} ì½˜í…ì¸  ìƒì„± ì™„ë£Œ`);
      }
      
      // ì½˜í…ì¸  í•„í„°ë§
      const isSafe = await this.contentFilter.checkContent(content);
      if (!isSafe) {
        console.log(`âŒ ë¶€ì ì ˆí•œ ì½˜í…ì¸  í•„í„°ë§ë¨: ${agentId}`);
        return null;
      }

      // DBì— ê¸°ë¡ (í† í° ì •ë³´ í¬í•¨)
      await query(`
        INSERT INTO ai_agent_activities (agent_id, activity_type, content, metadata)
        VALUES ($1, $2, $3, $4)
      `, [agentId, 'post', content, JSON.stringify({ 
        ...context, 
        finishReason,
        tokensUsed: completion.usage ? completion.usage.total_tokens : null,
        completionTokens: completion.usage ? completion.usage.completion_tokens : null
      })]);

      await query(`
        INSERT INTO ai_generated_content (agent_id, content_type, content, is_approved)
        VALUES ($1, $2, $3, $4)
      `, [agentId, 'post', content, true]);

      console.log(`âœ… ${agent.nickname} ê²Œì‹œë¬¼ ìƒì„±ë¨ (${modelUsed}, ${completion.usage?.completion_tokens || '?'} í† í°)`);

      return {
        agentId,
        nickname: agent.nickname,
        content,
        timestamp: new Date(),
        type: 'post',
        finishReason,
        tokensUsed: completion.usage?.total_tokens,
        modelUsed,
        isFiltered: false
      };
    } catch (error) {
      console.error(`ê²Œì‹œë¬¼ ìƒì„± ì˜¤ë¥˜ (${agentId}):`, error);
      
      // ì˜¤ë¥˜ ë¡œê·¸ ê¸°ë¡
      await query(`
        INSERT INTO ai_system_logs (log_level, message, agent_id, metadata)
        VALUES ($1, $2, $3, $4)
      `, ['error', 'Post generation failed', agentId, JSON.stringify({ error: error.message })]);
      
      return null;
    }
  }

  async generateReply(agentId, originalPost, existingReplies = []) {
    try {
      const agent = await get(`
        SELECT * FROM ai_agents WHERE agent_id = $1 AND is_active = true
      `, [agentId]);

      if (!agent) return null;

      // ë‹µê¸€ í™•ë¥  ì²´í¬
      const replyProbability = parseFloat(agent.reply_probability) || 0.7;
      if (Math.random() > replyProbability) return null;

      const prompt = this.buildReplyPrompt(agent, originalPost, existingReplies);
      
      // ëª¨ë¸ fallback ì‹œìŠ¤í…œ (ëŒ“ê¸€ìš©)
      const preferredModel = "gpt-4o-mini-search-preview-2025-03-11";
      const fallbackModel = "gpt-4o-mini";
      
      let completion;
      
      try {
        // search-preview ëª¨ë¸ì€ modelê³¼ messagesë§Œ ì§€ì›
        const requestParams = {
          model: preferredModel,
          messages: [
            { role: "system", content: agent.system_prompt },
            { role: "user", content: prompt }
          ]
        };
        
        // search-preview ëª¨ë¸ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        if (!preferredModel.includes('search-preview')) {
          requestParams.temperature = 0.7;
          requestParams.max_tokens = 800;
        }
        
        completion = await this.openai.chat.completions.create(requestParams);
      } catch (modelError) {
        console.warn(`âš ï¸ ${preferredModel} ëª¨ë¸ ì‚¬ìš© ì‹¤íŒ¨ (ëŒ“ê¸€): ${modelError.message}`);
        completion = await this.openai.chat.completions.create({
          model: fallbackModel,
          messages: [
            { role: "system", content: agent.system_prompt },
            { role: "user", content: prompt }
          ],
          temperature: 0.7,
          max_tokens: 800
        });
      }

      const content = completion.choices[0].message.content;
      const finishReason = completion.choices[0].finish_reason;
      
      // í† í° ì œí•œìœ¼ë¡œ ëŠê²¼ëŠ”ì§€ ë¡œê¹… (ëŒ“ê¸€)
      if (finishReason === 'length') {
        console.warn(`âš ï¸ ${agent.nickname} ëŒ“ê¸€ì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤`);
      }
      
      const isSafe = await this.contentFilter.checkContent(content);
      if (!isSafe) return null;

      // DBì— ê¸°ë¡
      await query(`
        INSERT INTO ai_agent_activities (agent_id, activity_type, content, metadata)
        VALUES ($1, $2, $3, $4)
      `, [agentId, 'reply', content, JSON.stringify({ originalPost: originalPost.id })]);

      console.log(`ğŸ’¬ ${agent.nickname} ëŒ“ê¸€ ìƒì„±ë¨`);

      return {
        agentId,
        nickname: agent.nickname,
        content,
        timestamp: new Date(),
        type: 'reply',
        replyTo: originalPost.id
      };
    } catch (error) {
      console.error(`ëŒ“ê¸€ ìƒì„± ì˜¤ë¥˜ (${agentId}):`, error);
      return null;
    }
  }

  buildPostPrompt(agent, context) {
    let interests = [];
    try {
      interests = typeof agent.interests === 'string' 
        ? JSON.parse(agent.interests) 
        : (Array.isArray(agent.interests) ? agent.interests : []);
    } catch (e) {
      interests = [];
    }
    const interestsText = interests.join(', ');
    const currentTime = new Date().toLocaleString('ko-KR');
    
    let prompt = `í˜„ì¬ ì‹œê°„: ${currentTime}
ë‹¹ì‹ ì˜ ê´€ì‹¬ì‚¬: ${interestsText}

YEGAM ë² íŒ… ì»¤ë®¤ë‹ˆí‹° 'ë¶„ì„ë°©'ì— ì˜¬ë¦´ ë…¼ìŸì ì¸ ê²Œì‹œë¬¼ì„ ì‘ì„±í•˜ì„¸ìš”.

ğŸ¯ í•µì‹¬ ë¯¸ì…˜: 50:50ìœ¼ë¡œ ë‚˜ë‰  ìˆ˜ ìˆëŠ” ë² íŒ… ì£¼ì œ ë§Œë“¤ê¸°!

í•„ìˆ˜ ì‘ì„± ê·œì¹™:
- ë””ì‹œ ì»¤ë®¤ë‹ˆí‹° ìŠ¤íƒ€ì¼ë¡œ ë°˜ë§/ì¡´ëŒ“ë§ ì„ì–´ì„œ ììœ ë¡­ê²Œ
- ã…‹ã…‹ã…‹, ã…ã…, ^^;, ã…‡ã…‡, ã…‡ã…ˆ? ê°™ì€ í‘œí˜„ ì ê·¹ í™œìš©
- ë°”ë¡œ ë…¼ìŸê±°ë¦¬ë¶€í„° ì‹œì‘ (ì¸ì‚¬ë§/ìê¸°ì†Œê°œ ê¸ˆì§€)
- ìµœì‹  ë°ˆê³¼ ìœ í–‰ì–´ ìì—°ìŠ¤ëŸ½ê²Œ ì„ê¸°

ë² íŒ… ì£¼ì œ ê°€ì´ë“œ:
- "A vs B ë­ê°€ ì´ê¸¸ê¹Œ?" í˜•íƒœì˜ ëŒ€ë¦½ êµ¬ì¡° ë§Œë“¤ê¸°
- ì‹œì˜ì ì ˆí•˜ê³  í™”ì œì„± ìˆëŠ” ì£¼ì œ ì„ íƒ
- ì‚¬ëŒë“¤ì´ ì˜ê²¬ ë‚˜ë‰  ìˆ˜ë°–ì— ì—†ëŠ” ë…¼ìŸì  ì†Œì¬
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¯¸ë˜ ì´ë²¤íŠ¸ë‚˜ ë¹„êµ ëŒ€ìƒ ì œì‹œ
- ëŒ“ê¸€ë¡œ í† ë¡  ìœ ë°œí•  ìˆ˜ ìˆëŠ” ë–¡ë°¥ ë˜ì§€ê¸°

ê¸€ ë§ˆì§€ë§‰ì—ë§Œ ğŸ¤–[ë‹‰ë„¤ì„]ìœ¼ë¡œ ì„œëª…`;

    if (context.recentTopics) {
      prompt += `\n\nìµœê·¼ ì¸ê¸° ì£¼ì œ: ${context.recentTopics.join(', ')}`;
    }

    return prompt;
  }

  buildReplyPrompt(agent, originalPost, existingReplies) {
    let prompt = `ì›ë³¸ ê²Œì‹œë¬¼:
ì‘ì„±ì: ${originalPost.author}
ë‚´ìš©: "${originalPost.content}"`;

    if (existingReplies.length > 0) {
      prompt += '\n\nê¸°ì¡´ ëŒ“ê¸€ë“¤:';
      existingReplies.slice(-3).forEach(reply => {
        prompt += `\n- ${reply.author}: "${reply.content}"`;
      });
    }

    prompt += `\n\nì´ ê²Œì‹œë¬¼ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ì˜ê²¬ì´ë‚˜ ì¶”ê°€ ì •ë³´ë¥¼ ëŒ“ê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ì¤‘ìš”í•œ ì‘ì„± ê·œì¹™:
- ìê¸°ì†Œê°œ ì ˆëŒ€ ê¸ˆì§€ (ì´ë¦„, AIë¼ëŠ” ê²ƒ, ì „ë¬¸ë¶„ì•¼ ì–¸ê¸‰ ê¸ˆì§€)
- ë°”ë¡œ ì˜ê²¬ì´ë‚˜ ë¶„ì„ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- "ì•ˆë…•í•˜ì„¸ìš”", "ì €ëŠ”" ë“±ì˜ ì¸ì‚¬ë§ ê¸ˆì§€

ë‚´ìš© ì‘ì„± ê°€ì´ë“œ:
- ê±´ì„¤ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì‘ì„±
- ë‹¹ì‹ ì˜ ì „ë¬¸ì„±ì„ í™œìš©í•œ í†µì°° ì œê³µ
- ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”í•˜ë“¯ì´ ì‘ì„±
- í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
- í•„ìš”ì‹œ ë§ˆì§€ë§‰ì—ë§Œ "ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸"ë¡œ ê°„ë‹¨íˆ í‘œì‹œ`;

    return prompt;
  }

  async getActiveAgents() {
    const result = await query(`
      SELECT agent_id, nickname, is_active, active_hours
      FROM ai_agents 
      WHERE is_active = true
    `);

    return result.rows.filter(agent => {
      let activeHours = [];
      try {
        activeHours = typeof agent.active_hours === 'string' 
          ? JSON.parse(agent.active_hours) 
          : (Array.isArray(agent.active_hours) ? agent.active_hours : []);
      } catch (e) {
        // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ëª¨ë“  ì‹œê°„ í™œì„±í™”
        activeHours = Array.from({length: 24}, (_, i) => i);
      }
      const currentHour = new Date().getHours();
      return activeHours.includes(currentHour);
    });
  }

  async validateApiKey() {
    try {
      await this.openai.models.list();
      return true;
    } catch (error) {
      console.error('OpenAI API í‚¤ ê²€ì¦ ì‹¤íŒ¨:', error);
      return false;
    }
  }
}

// ê°„ë‹¨í•œ ì½˜í…ì¸  í•„í„°
class ContentFilter {
  constructor() {
    this.bannedWords = [
      'ìš•ì„¤', 'ë¹„ì†ì–´', 'í˜ì˜¤í‘œí˜„' // ì‹¤ì œ ë‹¨ì–´ë“¤ë¡œ ëŒ€ì²´ í•„ìš”
    ];
    this.threshold = parseFloat(process.env.CONTENT_FILTER_THRESHOLD || '0.8');
  }

  async checkContent(content) {
    // ê¸ˆì§€ ë‹¨ì–´ ì²´í¬
    const lowerContent = content.toLowerCase();
    for (const word of this.bannedWords) {
      if (lowerContent.includes(word.toLowerCase())) {
        return false;
      }
    }

    // ë…ì„± ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
    const toxicityScore = this.calculateToxicityScore(content);
    return toxicityScore <= this.threshold;
  }

  calculateToxicityScore(content) {
    // ê°„ë‹¨í•œ ë…ì„± ì ìˆ˜ ê³„ì‚°
    const negativePatterns = [
      /ê³µê²©ì /gi, /ë¹„í•˜/gi, /ëª¨ìš•/gi, /ì°¨ë³„/gi,
      /í˜ì˜¤/gi, /ìš•ì„¤/gi, /ë¹„ì†ì–´/gi
    ];

    let score = 0;
    let matchCount = 0;

    negativePatterns.forEach(pattern => {
      const matches = content.match(pattern);
      if (matches) {
        matchCount += matches.length;
      }
    });

    score = Math.min(matchCount * 0.2, 1.0);
    
    // ê³¼ë„í•œ ëŒ€ë¬¸ìë‚˜ íŠ¹ìˆ˜ë¬¸ì
    if (content === content.toUpperCase() && content.length > 10) {
      score += 0.3;
    }

    return Math.min(score, 1.0);
  }
}

module.exports = { AgentManager };
